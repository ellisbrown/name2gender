{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "# rnn = torch.load('gender-rnn-classification.pt')\n",
    "\n",
    "from data_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size,batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(name_tensor):\n",
    "    hidden = rnn.init_hidden()\n",
    "    \n",
    "    for i in range(name_tensor.size()[0]):\n",
    "        output, hidden = rnn(name_tensor[i], hidden)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def predict(name, n_predictions=2):\n",
    "    output = evaluate(Variable(name_to_tensor(name)))\n",
    "\n",
    "    # Get top N categories\n",
    "    topv, topi = output.data.topk(n_predictions, 1, True)\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(n_predictions):\n",
    "        value = topv[0][i]\n",
    "        gender_index = topi[0][i]\n",
    "        print('(%.2f) %s' % (value, all_genders[gender_index]))\n",
    "        predictions.append([value, all_genders[gender_index]])\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 128\n",
    "n_epochs = 100000\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "batch_size = 16\n",
    "visdom = False\n",
    "num_workers = 2\n",
    "start_iter = 0 # Begin counting iterations starting from this value (should be used with resume)\n",
    "max_iter = 120000\n",
    "stepvalues = (80000, 100000, 120000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnn = RNN(n_letters, n_hidden, n_genders)\n",
    "optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = NameGenderDataset(testset)\n",
    "data_loader = data.DataLoader(dataset, 30, num_workers=2, shuffle=True, collate_fn=name_gender_collate)\n",
    "batch_iterator = iter(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names, genders = next(batch_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6782'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(len(valset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vittoriano male\n",
      "eitelbert male\n",
      "sigtraud female\n",
      "semarias male\n",
      "richelle female\n",
      "mengquan male\n",
      "hennadiy male\n",
      "andriena female\n",
      "volkart male\n",
      "reyanna female\n",
      "renbiao male\n",
      "kenyaum male\n",
      "sanura female\n",
      "miylah female\n",
      "masino male\n",
      "jodice male\n",
      "houwei male\n",
      "gavina female\n",
      "allart male\n",
      "aimery male\n",
      "uniya female\n",
      "tyski male\n",
      "sisko female\n",
      "norio male\n",
      "niesa female\n",
      "lolan male\n",
      "jacks male\n",
      "frida female\n",
      "dupre male\n",
      "duice female\n"
     ]
    }
   ],
   "source": [
    "for name, gender in zip(names,genders):\n",
    "    print(tensor_to_name(name), all_genders[gender.data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    1     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.LongTensor of size 1x26]\n",
      "\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     1     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.LongTensor of size 1x26]\n",
      "\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    1     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.LongTensor of size 1x26]\n",
      "\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     0     0     1     0     0     0     0     0     0     0     0\n",
      "[torch.LongTensor of size 1x26]\n",
      "\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    1     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.LongTensor of size 1x26]\n",
      "\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    1     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.LongTensor of size 1x26]\n",
      "\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.LongTensor of size 1x26]\n",
      "\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.LongTensor of size 1x26]\n",
      "\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.LongTensor of size 1x26]\n",
      "\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.LongTensor of size 1x26]\n",
      "\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.LongTensor of size 1x26]\n",
      "\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.LongTensor of size 1x26]\n",
      "\n",
      "aparna\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "ret = \"\"\n",
    "for letter_tensor in names[19].split(1):\n",
    "    print(letter_tensor)\n",
    "    nz = letter_tensor.data.nonzero()\n",
    "    if torch.numel(nz) != 0:\n",
    "        ret += (string.ascii_lowercase[nz[0,1]])\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "# torch.zeros(1,128)\n",
    "# names[19].split(1)[0]\n",
    "print('.' , end=\"\")\n",
    "print('.' , end=\"\")\n",
    "print('.' , end=\"\")\n",
    "print()\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cat received an invalid combination of arguments - got (tuple, int), but expected one of:\n * (sequence[torch.LongTensor] seq)\n * (sequence[torch.LongTensor] seq, int dim)\n      didn't match because some of the arguments have invalid types: (!tuple!, int)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-7992e6627efb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Anaconda3-4.4.0-Linux-x86_64/envs/jupyter-atp/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcat\u001b[0;34m(iterable, dim)\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mConcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda3-4.4.0-Linux-x86_64/envs/jupyter-atp/lib/python3.5/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, dim, *inputs)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cat received an invalid combination of arguments - got (tuple, int), but expected one of:\n * (sequence[torch.LongTensor] seq)\n * (sequence[torch.LongTensor] seq, int dim)\n      didn't match because some of the arguments have invalid types: (!tuple!, int)\n"
     ]
    }
   ],
   "source": [
    "torch.cat((names[19].split(1)[0], torch.zeros(1,128)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_workers = 2\n",
    "start_ep = 1 # Begin counting iterations starting from this value (should be used with resume)\n",
    "end_ep = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ep = end_ep - start_ep + 1\n",
    "len(dataset) % batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mini = NameGenderDataset(split_dataset(0.9,0.0005)[1])\n",
    "miniloader = data.DataLoader(mini, batch_size=4, num_workers=2,\n",
    "                                  shuffle=True, collate_fn=name_gender_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import progressbar\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bar = progressbar.ProgressBar()\n",
    "for i in bar(range(100)):\n",
    "    time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "progressbar.streams.wrap_stderr()\n",
    "logging.basicConfig()\n",
    "\n",
    "bar = progressbar.ProgressBar()\n",
    "for i in bar(range(10)):\n",
    "    logging.error('Got %d', i)\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_mini():\n",
    "    it = iter(miniloader)\n",
    "    batch = 0\n",
    "    while(True):\n",
    "        try:\n",
    "            batch += 1\n",
    "            nm,gn = next(it)\n",
    "            print(\"Batch #\", batch, len(nm))\n",
    "            for name in nm:\n",
    "                print(tensor_to_name(name))\n",
    "        except StopIteration:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch # 1 4\n",
      "charlottle\n",
      "velizara\n",
      "lawahiz\n",
      "gilmore\n",
      "Batch # 2 4\n",
      "orbelin\n",
      "katrina\n",
      "brigitt\n",
      "frimet\n",
      "Batch # 3 4\n",
      "ekkehardt\n",
      "schuylar\n",
      "jingtian\n",
      "mayana\n",
      "Batch # 4 1\n",
      "janikqua\n"
     ]
    }
   ],
   "source": [
    "run_mini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch # 1\n",
      "ekkehardt\n",
      "orbelin\n",
      "lawahiz\n",
      "mayana\n",
      "Batch # 2\n",
      "velizara\n",
      "schuylar\n",
      "janikqua\n",
      "gilmore\n",
      "Batch # 3\n",
      "charlottle\n",
      "jingtian\n",
      "katrina\n",
      "brigitt\n",
      "Batch # 4\n",
      "frimet\n"
     ]
    }
   ],
   "source": [
    "run_mini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch # 1\n",
      "charlottle\n",
      "ekkehardt\n",
      "janikqua\n",
      "orbelin\n",
      "Batch # 2\n",
      "schuylar\n",
      "gilmore\n",
      "brigitt\n",
      "mayana\n",
      "Batch # 3\n",
      "velizara\n",
      "lawahiz\n",
      "katrina\n",
      "frimet\n",
      "Batch # 4\n",
      "jingtian\n"
     ]
    }
   ],
   "source": [
    "run_mini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "   0.7304  0.7241  0.7746  0.0598  0.3045  0.9179  0.9519  0.5221  0.9286\n",
       "\n",
       "Columns 9 to 17 \n",
       "   0.9225  0.5350  0.8277  0.3725  0.5689  0.7781  0.5558  0.1031  0.3205\n",
       "\n",
       "Columns 18 to 25 \n",
       "   0.8895  0.6413  0.3493  0.8204  0.4681  0.7177  0.5352  0.5811\n",
       "\n",
       "(1 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "   0.3848  0.5293  0.2402  0.5740  0.7639  0.8949  0.5400  0.3663  0.6535\n",
       "\n",
       "Columns 9 to 17 \n",
       "   0.7766  0.8432  0.1905  0.7575  0.9952  0.1339  0.7068  0.1554  0.3810\n",
       "\n",
       "Columns 18 to 25 \n",
       "   0.7105  0.6054  0.9141  0.6224  0.1957  0.8083  0.9247  0.8236\n",
       "\n",
       "(2 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "   0.9449  0.5020  0.1777  0.0459  0.5663  0.4822  0.5499  0.3416  0.9190\n",
       "\n",
       "Columns 9 to 17 \n",
       "   0.1089  0.7138  0.6793  0.7103  0.1771  0.2281  0.5325  0.2385  0.4749\n",
       "\n",
       "Columns 18 to 25 \n",
       "   0.4839  0.8185  0.5266  0.1435  0.4592  0.5884  0.2337  0.9653\n",
       "\n",
       "(3 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "   0.0738  0.7432  0.7410  0.7047  0.8022  0.5676  0.2255  0.8328  0.0992\n",
       "\n",
       "Columns 9 to 17 \n",
       "   0.5631  0.5902  0.3034  0.6922  0.6700  0.5700  0.6975  0.7024  0.3805\n",
       "\n",
       "Columns 18 to 25 \n",
       "   0.3462  0.7270  0.0515  0.2717  0.8763  0.5969  0.0649  0.5736\n",
       "\n",
       "(4 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "   0.2616  0.4733  0.5981  0.2820  0.7570  0.7698  0.9060  0.0388  0.5180\n",
       "\n",
       "Columns 9 to 17 \n",
       "   0.4665  0.7201  0.5998  0.8232  0.8035  0.4054  0.0527  0.7214  0.5203\n",
       "\n",
       "Columns 18 to 25 \n",
       "   0.8033  0.4002  0.5981  0.6770  0.4044  0.8570  0.5403  0.5140\n",
       "\n",
       "(5 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "   0.6685  0.3776  0.9402  0.2218  0.8735  0.7058  0.2612  0.3663  0.2309\n",
       "\n",
       "Columns 9 to 17 \n",
       "   0.7368  0.0438  0.3015  0.0948  0.2911  0.8247  0.9827  0.6270  0.4557\n",
       "\n",
       "Columns 18 to 25 \n",
       "   0.6224  0.7309  0.5392  0.9527  0.6348  0.7909  0.2403  0.5781\n",
       "\n",
       "(6 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "   0.1083  0.2845  0.0659  0.7389  0.8230  0.3668  0.3283  0.2216  0.3540\n",
       "\n",
       "Columns 9 to 17 \n",
       "   0.1452  0.5815  0.2521  0.5972  0.7201  0.1268  0.4061  0.5370  0.0198\n",
       "\n",
       "Columns 18 to 25 \n",
       "   0.0330  0.8233  0.0683  0.5755  0.5638  0.3798  0.1790  0.5594\n",
       "[torch.FloatTensor of size 7x1x26]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = Variable(torch.rand(7,1,26))\n",
    "v.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       " 0.7304  0.7241  0.7746  0.0598  0.3045  0.9179  0.9519  0.5221  0.9286  0.9225\n",
       "\n",
       "Columns 10 to 19 \n",
       " 0.5350  0.8277  0.3725  0.5689  0.7781  0.5558  0.1031  0.3205  0.8895  0.6413\n",
       "\n",
       "Columns 20 to 29 \n",
       " 0.3493  0.8204  0.4681  0.7177  0.5352  0.5811  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 30 to 39 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 40 to 49 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 50 to 59 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 60 to 69 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 70 to 79 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 80 to 89 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 90 to 99 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 100 to 109 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 110 to 119 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 120 to 129 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 130 to 139 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 140 to 149 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 150 to 153 \n",
       " 0.0000  0.0000  0.0000  0.0000\n",
       "[torch.FloatTensor of size 1x154]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((v[0].float(),torch.zeros(1,128)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cat received an invalid combination of arguments - got (tuple, int), but expected one of:\n * (sequence[torch.LongTensor] seq)\n * (sequence[torch.LongTensor] seq, int dim)\n      didn't match because some of the arguments have invalid types: (!tuple!, int)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-ef14d7a1b027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda3-4.4.0-Linux-x86_64/envs/jupyter-atp/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-db3b1b100f41>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi2h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi2o\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda3-4.4.0-Linux-x86_64/envs/jupyter-atp/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcat\u001b[0;34m(iterable, dim)\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mConcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda3-4.4.0-Linux-x86_64/envs/jupyter-atp/lib/python3.5/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, dim, *inputs)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cat received an invalid combination of arguments - got (tuple, int), but expected one of:\n * (sequence[torch.LongTensor] seq)\n * (sequence[torch.LongTensor] seq, int dim)\n      didn't match because some of the arguments have invalid types: (!tuple!, int)\n"
     ]
    }
   ],
   "source": [
    "hidden = rnn.init_hidden()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for i in range(names.size(1)):\n",
    "    output, hidden = rnn(names[:,i], hidden)\n",
    "\n",
    "loss = criterion(output, genders)\n",
    "loss.backward()\n",
    "\n",
    "optimizer.step()\n",
    "\n",
    "return output, loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 12 \n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     1     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     1     0     0     0     0\n",
       "    0     0     0     0     1     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "\n",
       "Columns 13 to 25 \n",
       "    0     1     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     1     0     0     0     0     0\n",
       "[torch.LongTensor of size 5x26]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       â‹±       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "[torch.FloatTensor of size 1x128x16]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] [--batch_size BATCH_SIZE] [--num_workers NUM_WORKERS]\n",
      "                   [--log_iters LOG_ITERS] [--weights WEIGHTS]\n",
      "__main__.py: error: unrecognized arguments: -f /jupyter-runtime/kernel-c116fc5b-96ed-4782-ae2e-d6ec5b5f4748.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Anaconda3-4.4.0-Linux-x86_64/envs/jupyter-atp/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    hours, rem = divmod(now-since, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    return \"{:0>2}h {:0>2}m {:0>2}s\".format(int(hours),int(minutes),int(seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00h 00m 01s'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time.time()\n",
    "time.sleep(1.55)\n",
    "time_since(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val = split_dataset(0.75,0.01)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1356"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from model import RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RNN (\n",
       "  (i2h): Linear (154 -> 128)\n",
       "  (i2o): Linear (154 -> 2)\n",
       "  (softmax): LogSoftmax ()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Loading weights...')\n",
    "rnn = RNN(n_letters, n_hidden, n_genders)\n",
    "rnn.load_state_dict(torch.load('weights/gender_rnn_epoch21000.pth'))\n",
    "rnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _evaluate(name_tensor):\n",
    "    hidden = rnn.init_hidden()\n",
    "    \n",
    "    for letter_tensor in name_tensor:\n",
    "        letter_tensor.data.unsqueeze_(0)\n",
    "        output, hidden = rnn(letter_tensor, hidden)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def validate(dataset=valset):\n",
    "    dataset = NameGenderDataset(dataset)\n",
    "    data_loader = data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers,\n",
    "                                  shuffle=True, collate_fn=name_gender_collate)\n",
    "    \n",
    "    # iterate over all minibatches\n",
    "    start = time.time()\n",
    "    batch_iterator = iter(data_loader)\n",
    "    cum = 0\n",
    "    while(True):\n",
    "        try:\n",
    "            print(time_since(start))\n",
    "            names_tensor, genders_tensor = next(batch_iterator)\n",
    "            for name_tensor, gender_tensor in zip(names_tensor,genders_tensor):\n",
    "                gt = all_genders[gender_tensor.data[0]]\n",
    "                name = tensor_to_name(name_tensor)\n",
    "                output = _evaluate(name_tensor)\n",
    "                topv, topi = output.data.topk(k=1, dim=1, largest=True)\n",
    "                guess = all_genders[topi[0][0]]\n",
    "                cum += 1 if guess == gt else 0\n",
    "        except StopIteration:\n",
    "            break\n",
    "    acc = cum / len(dataset)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00h 00m 00s\n",
      "00h 00m 34s\n",
      "00h 00m 50s\n",
      "00h 01m 19s\n",
      "00h 01m 52s\n",
      "00h 02m 29s\n",
      "00h 02m 59s\n",
      "00h 03m 29s\n",
      "00h 04m 04s\n",
      "00h 04m 42s\n",
      "00h 05m 11s\n",
      "00h 05m 50s\n",
      "00h 06m 20s\n",
      "00h 06m 57s\n",
      "00h 07m 31s\n",
      "00h 08m 04s\n",
      "00h 08m 37s\n",
      "00h 09m 07s\n",
      "00h 09m 46s\n",
      "00h 10m 20s\n",
      "00h 10m 49s\n",
      "00h 11m 22s\n",
      "00h 11m 41s\n",
      "00h 12m 16s\n",
      "00h 12m 49s\n",
      "00h 13m 21s\n",
      "00h 14m 09s\n",
      "00h 14m 33s\n",
      "00h 14m 59s\n",
      "00h 15m 42s\n",
      "00h 16m 20s\n",
      "00h 16m 43s\n",
      "00h 17m 11s\n",
      "00h 17m 37s\n",
      "00h 18m 12s\n",
      "00h 18m 41s\n",
      "00h 19m 15s\n",
      "00h 19m 49s\n",
      "00h 20m 19s\n",
      "00h 20m 48s\n",
      "00h 21m 15s\n",
      "00h 21m 41s\n",
      "00h 22m 10s\n",
      "00h 22m 23s\n",
      "00h 22m 53s\n",
      "00h 23m 23s\n",
      "00h 23m 44s\n",
      "00h 24m 10s\n",
      "00h 24m 51s\n",
      "00h 25m 16s\n",
      "00h 25m 51s\n",
      "00h 26m 26s\n",
      "00h 27m 02s\n",
      "00h 27m 30s\n",
      "00h 28m 24s\n",
      "00h 28m 52s\n",
      "00h 29m 16s\n",
      "00h 29m 46s\n",
      "00h 30m 17s\n",
      "00h 30m 51s\n",
      "00h 31m 14s\n",
      "00h 31m 50s\n",
      "00h 32m 29s\n",
      "00h 32m 50s\n",
      "00h 33m 14s\n",
      "00h 33m 37s\n",
      "00h 34m 05s\n",
      "00h 34m 45s\n",
      "00h 35m 18s\n",
      "00h 35m 57s\n",
      "00h 36m 33s\n",
      "00h 37m 08s\n",
      "00h 37m 40s\n",
      "00h 38m 03s\n",
      "00h 38m 34s\n",
      "00h 39m 04s\n",
      "00h 39m 39s\n",
      "00h 40m 15s\n",
      "00h 41m 05s\n",
      "00h 41m 58s\n",
      "00h 42m 27s\n",
      "00h 43m 03s\n",
      "00h 43m 31s\n",
      "00h 44m 07s\n",
      "00h 44m 41s\n",
      "00h 45m 06s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7315634218289085"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00h 00m 00s\n",
      "00h 00m 07s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(val[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101730"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33910"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
